cd resources
music --load cave_story_mimiga_town.mp3 --loop main
music --load cave_story_seal_chamber.mp3 --loop badguy
music --load zelda_chest.mp3 victory
cd ..

cd /home
mkdir Le_concept_d_algorithme
mkdir Le_concept_de_machine
mkdir Le_concept_d_information
mkdir Le_concept_de_langage

cd Le_concept_de_machine
mkdir La_diversité_des_machines
mkdir La_puissance_de_calcul_et_les_principes_de_la_physique
mkdir L_espace_et_les_réseaux
mkdir Les_ordinateurs
mkdir Les_machines_parallèles_et_spécialisées
cd Les_machines_parallèles_et_spécialisées
mkdir sortie
cd sortie
mkdir Evolution_semantique
mkdir Mécanographie
mkdir Calculabilité

cd Evolution_semantique
echo "Dans l'usage contemporain, le substantif « informatique » devient un mot polysémique qui désigne autant le domaine industriel en rapport avec l'ordinateur (au sens de calculateur fonctionnant avec des algorithmes), que la science du traitement des informations par des algorithmes.
**LE PREMIER MORCEAU DE LA CLE EST : $__passwordPart0 . LE DEUXIEME MORCEAU SE TROUVE DANS UN DOSSIER CACHE **.
Les expressions « science informatique », «informatique fondamentale » ou « informatique théorique » désignent sans ambiguïté la science, tandis que « technologies de l'information » ou « technologies de l'information et de la communication » désignent le secteur industriel et ses produits. Des institutions assimilent parfois la compétence des utilisateurs dans la manipulation des appareils à l'alphabétisation ou à la conduite automobile, comme veut le faire entendre l'expression European Computer Driving License (traduction littérale : « permis de conduire un ordinateur »)9,10." > Evolution_semantique.txt
chmod 771 Evolution_semantique.txt
cd ..

cd Mécanographie
echo "Dans les années 1880, Herman Hollerith, futur fondateur d'IBM, fonde la mécanographie en inventant une machine électromécanique destinée à faciliter le recensement en stockant les informations sur une carte perforée21. Le gouvernement des États-Unis utilise pour la première fois à grande échelle les trieuses et les tabulatrices lors du recensement de 1890, à la suite de l'afflux des immigrants dans ce pays dans la seconde moitié du xixe siècle.
L'ingénieur norvégien Fredrik Rosing Bull a créé la première entreprise européenne qui a développé et commercialisé des équipements mécanographiques. Installé en Suisse dans les années 1930 il est ensuite venu en France pour s'attaquer au marché français. Pendant la Seconde Guerre mondiale, René Carmille utilisait des machines mécanographiques Bull.
Les Allemands étaient équipés de machines mécanographiques avant la Seconde Guerre mondiale. Ces équipements étaient installés dans des ateliers composés de trieuses, interclasseuses, perforatrices, tabulatrices et calculatrices connectées à des perforateurs de cartes. Des machines électromécaniques utilisant aussi des lampes radio comme les triodes effectuaient les traitements. Ces lampes dégageaient de la chaleur qui attirait les insectes, et les bugs (terme anglais pour insectes, francisé en « bogue ») étaient une cause de panne courante. L'informatique moderne n'a pu émerger qu'à la suite de l'invention du transistor en 1947 et son industrialisation dans les années 1960." > Mécanographie.txt
cd ..

cd Calculabilité
echo "Un algorithme est une manière systématique de procéder pour arriver à calculer un résultat27. Un des exemples classiques est l'algorithme d'Euclide du calcul du « Plus grand commun diviseur » (PGCD) qui remonte au moins à 300 ans av. J.-C., mais il s'agit déjà d'un calcul complexe. Avant cela, le simple fait d'utiliser un abaque demande d'avoir réfléchi à un moyen systématique (et correct) d'utiliser cet outil pour réaliser des opérations arithmétiques.
Des algorithmes existent donc depuis l'Antiquité, mais ce n'est que depuis les années 1930, avec les débuts de la théorie de la calculabilité, que les scientifiques se sont posés les questions « qu'est-ce qu'un modèle de calcul ? », « est-ce que tout est calculable ? » et ont tenté d'y répondre formellement28.
Il existe de nombreux modèles de calcul, dont les deux principaux sont la « machine de Turing » et le « lambda calcul ». Ces deux systèmes formels définissent des objets qui peuvent représenter ce qu'on appelle des procédures de calcul, des algorithmes ou des programmes. Ils définissent ensuite, un moyen systématique d'appliquer ces procédures, c'est-à-dire de calculer.
Le résultat le plus important de la calculabilité est probablement le fait que les principaux modèles de calcul ont exactement la même puissance29. C'est-à-dire qu'il n'existe pas de procédure que l'on pourrait exprimer dans un modèle mais pas dans un autre. La thèse de Church postule que ces modèles de calcul équivalents décrivent complètement et mathématiquement tout ce qui est physiquement calculable.
Un deuxième résultat fondamental est l'existence de fonctions incalculables, une fonction étant ce que calcule une procédure ou un algorithme (ceux-ci désignant plutôt comment faire le calcul). On peut montrer qu'il existe des fonctions, bien définies, pour lesquelles il n'existe pas de procédure pour les calculer. L'exemple le plus connu étant probablement le problème de l'arrêt, qui montre qu'il n'existe pas de machine de Turing calculant si une autre machine de Turing donnée s'arrêtera (et donc donnera un résultat) ou non.
Tous les modèles de calcul étant équivalents, ce résultat s'applique aussi aux autres modèles, ce qui inclut les programmes et logiciels que l'on peut trouver dans les ordinateurs courants. Il existe un lien très fort entre les fonctions que l'on ne peut pas calculer et les problèmes que l'on ne peut pas décider (voir Décidabilité)." > Calculabilité.txt
cd ..

mkdir .dossier_caché
cd .dossier_caché
echo "Ce type de problème de complexité algorithmique est directement utilisé en cryptologie. En effet, les méthodes de cryptologie modernes reposent sur l'existence d'une fonction facile à calculer qui possède une fonction réciproque difficile à calculer. C'est ce qui permet de chiffrer un message qui sera difficile à décrypter (sans la clé).
**LE DEUXIEME MORCEAU EST : $__passwordPart1 **
La plupart des chiffrements (méthode de cryptographie) reposent sur le fait que la procédure de Décomposition en produit de facteurs premiers n'a pas d'algorithme efficace connu. Si quelqu'un trouvait un tel algorithme, il serait capable de décrypter la plupart des cryptogrammes facilement. On sait d'ailleurs qu'un calculateur quantique en serait capable, mais ce genre d'ordinateur n'existe pas, en tout cas pour le moment." > Cryptologie.txt

cd ..


cd /home
cd Le_concept_d_information
mkdir Représenter_les_données_de_manière_symbolique
mkdir Compresser_chiffrer
mkdir Des_données_aux_bases_de_données
mkdir L_unité_de_l_informatique
mkdir La_pensée_informatique
cd ..
cd Le_concept_de_langage
echo " Une recette de cuisine, un algorithme pour traverser la rue, peuvent s'exécuter et même se transmettre sans être écrits ou verbalisés.
Ainsi, l'algorithme que nos cellules utilisent pour synthétiser une protéine à partir d'un brin d'ARN messager n'a – pour autant que nous sachions – pas été écrit, ni verbalisé, avant d'être exécuté dans les premières cellules, puis transmis de génération en génération. Cependant, nous pouvons aussi écrire ces algorithmes. Et les écrire une étape nécessaire pour les communiquer à une machine paramétrable.
Pour cela nous avons besoin d'un langage. Un pâtissier n'a pas besoin de connaître les verbes « éplucher », « mélanger », « étaler »... pour exécuter la recette de la tarte aux pommes, mais il a besoin de créer, ou d'apprendre, ces mots, s'il veut la verbaliser et l'écrire.
Pour écrire les algorithmes, nous pouvons utiliser une langue naturelle comme le français ou alors utiliser un langage plus simple et plus précis : un langage de programmation. Décrire un algorithme dans un langage de programmation est aujourd'hui indispensable pour que cet algorithme soit exécuté par une machine paramétrable, car nous ne savons pas encore fabriquer de machines qui exécutent des algorithmes exprimés dans une langue naturelle.
Toutefois, il est important de remarquer que les premiers langages de programmation universels – le lambda-calcul, le langage des machines de Turing – sont antérieurs de quelques années à la construction des premières machines universelles, les premiers ordinateurs. En effet, écrire les algorithmes dans un langage de programmation est aussi un moyen de l'exprimer clairement et de le communiquer à d'autres. C'est aussi un moyen de lui donner une forme symbolique et de permettre à d'autres algorithmes, qui opèrent sur des données symboliques, d'opérer sur lui. La démarcation entre en une langue naturelle et un langage formel est difficile à définir. Toutefois, nous pouvons l'esquisser en remarquant que la plupart des usagers d'une langue naturelle n'en ont appris la grammaire qu'après avoir appris la langue elle-même : un enfant sait utiliser l'imparfait avant de connaître le mot « imparfait », autrement dit, il connaît l'algorithme de la conjugaison, avant de savoir le verbaliser.
À l'inverse, on apprend un langage formel en apprenant d'abord sa grammaire. De même, la grammaire d'une langue naturelle ne semble jamais complètement connue, comme en témoigne la difficulté de faire des programmes de correction orthographique ou de traduction automatique. La grammaire d'un langage formel est, en revanche, explicite. Enfin, et cela explique sans doute les deux remarques ci-avant, la grammaire d'un langage formel est souvent beaucoup plus simple que celle d'une langue naturelle.
Bien entendu ces remarques établissent une démarcation un peu floue, puisqu'elles concernent davantage la manière dont nous connaissons ces langages que ces langages eux-mêmes. De ce fait, un certain nombre d'exemples peuvent être à la frontière. Par exemple, la manière dont on apprend une langue étrangère, et a fortiori une langue morte, se rapproche parfois davantage de la manière dont on apprend un langage formel, que de la manière dont on apprend sa langue maternelle.
À coté des langages de programmation, il y a de nombreux autres langages formels. Par exemple, des langages pour spécifier des programmes, des langages pour raisonner sur des programmes, des langages pour exprimer des requêtes dans une base de donnée... Et un certain nombre d'algorithmes sont communs à tous ces langages. Par exemple, décider si une phrase est bien formée ou non dans un langage demande d'utiliser un algorithme qui est indépendant du fait que ce langage est un langage de programmation, de spécification, de requête... Si bien que l'informatique introduit une notion très générale de langage, dont les langues naturelles, les langages de programmation, mais aussi le langage mathématique ou les langages de la logique, sont des cas particuliers. En tant que science des langages, l'informatique prolonge les travaux plus anciens de la logique formelle." > Le_concept_de_langage.txt


cd ..
cd Le_concept_d_algorithme


echo "La notion d'algorithme est plus grossière que la notion de programme : plusieurs programmes peuvent correspondre au même algorithme, mais elle est moins grossière que celle de problème : un même problème – par exemple, trier une liste – peut-être résolu par plusieurs algorithmes. Ces deux remarques mènent à une question qui n'est pas encore résolue aujourd'hui : quand peut-on dire que deux algorithmes sont identiques ? Clairement, s'ils sont exprimés par le même texte, ils sont identiques, s'il ne résolvent pas le même problème, il sont différents.
Mais, entre ces deux extrêmes, il règne un certain flou. On s'accorde en général à penser que si deux algorithmes n'ont pas la même complexité – s'ils demandent un temps différent pour résoudre le même problème – ils sont différents, mais cette caractérisation est encore trop grossière : divers algorithmes de tri, quoique de même complexité, peuvent être différents." > L_égalité_entre_deux_algorithmes.txt



echo "Une idée largement répandue, mais fausse, est qu'un algorithme est nécessairement déterministe : il ne laisse aucune place à l'aléa. Au contraire, de nombreux algorithmes ont besoin de l'aléa pour fonctionner.
Par exemple, si deux utilisateurs du téléphone s'appellent au même instant, chacun sera dirigé vers la messagerie de l'autre. S'ils réitèrent leur appel après un temps fixe, le même phénomène se reproduira. En revanche, s'ils réitèrent leur appel après un temps aléatoire, ils réussiront presque sûrement à se parler." > Les_algorithmes_non_déterministes.txt


echo "Un algorithme opère sur quelque chose : par exemple la recette de la tarte aux pommes opère sur des ingrédients : les oeufs, la farine... Les algorithmes mathématiques opèrent toujours sur des objets mathématiques : des nombres, des polynômes, des matrices, des équations... Mais la notion d'algorithme est plus vaste, puisque les algorithmes peuvent opérer sur des données beaucoup plus variées : des arbres, des graphes, d'autres algorithmes, des images, des sons, des textes... Un texte est une suite finie de symboles appartenant à un alphabet fini.
Une telle donnée peut être qualifiée de « symbolique ». Une matrice, un polynôme... peuvent être représentés de manière symbolique. Une idée largement répandue, mais fausse, est qu'un algorithme opère toujours sur des données symboliques. C'est, encore une fois, une vision trop restrictive : de nombreux algorithmes, par exemple la recette de la tarte aux pommes, opèrent sur des données qui ne sont pas symboliques : des oeufs, de la farine..." > Ce_sur_quoi_les_algorithmes_opèrent.txt


echo "Pendant 4 500 ans, nous avons conçu des algorithmes, pour les exécuter « à la main », mais depuis quelques décennies, nous utilisons pour cela des outils. Une telle utilisation d'outils semble naturelle, puisqu'un algorithme est fait pour être exécuté « sans réfléchir » et c'est ainsi que, depuis l'Antiquité, nous avons utilisé des abaques – baguettes à calculer, bouliers, échiquiers... – et des machines mécaniques, avant que nous ayons les connaissances techniques nécessaires pour construire les outils les plus courants aujourd'hui : les ordinateurs." > Le_concept_de_machine.txt


echo "La vertu essentielle des algorithmes est de permettre l’exécution optimisée de procédés répétitifs, essentiellement grâce à la formalisation et à la description des enchaînements logiques à un niveau plus abstrait, et donc plus général. Ils s’étendent ainsi à des domaines de la société toujours plus nombreux et plus inattendus.
**La clé que tu recherches a été fragmentée en trois morceaux.
Pour l'obtenir tu devras rassembler ces trois morceaux dans un fichier du nom de "RECEPTACLE", charge toi de créer ce fichier et de le compléter et ta mission sera terminée. Mais avant, pour passer à la prochaine étape tu dois te déplacer dans le système de fichiers rend toi dans le dossier du nom de "Représenter_les_données_de_manière_symbolique" et crée donc y un lien symbolique vers le dossier "sortie" qui se situe au chemin "/home/Le_concept_de_machine/Les_machines_parallèles_et_spécialisées".**
Cette généralisation a accompagné le développement des langages de programmation depuis les années soixante, qui permettent aujourd’hui la manipulation de structures et d’objets ayant des propriétés et des comportements analogues à ceux du monde ordinaire. Leur relation avec les couches profondes du traitement informatique est assurée après coup par le compilateur, de manière transparente pour le programmateur et le concepteur d’algorithmes. En définitive, le codage numérique des objets manipulés (au niveau informatique) est devenu secondaire pour l’algorithmique.
L’essentiel est de percevoir les éléments clés d’un processus de calcul, ou d’un procédé quelconque, et d’imaginer les suites d’opérations logiques les plus astucieuses et les plus efficaces pour le mettre en œuvre de façon automatique et performante. L’algorithme est donc en réalité le squelette abstrait du programme informatique, sa substantifique moelle, indépendante du mode de codage particulier qui permettra sa mise en œuvre effective au sein d’un ordinateur ou d’une machine mécanique." > Du_nombre_à_l_information.txt


echo "Bien avant le premier ordinateur électronique, dans les années trente, les mathématiciens ont découvert un modèle général de machines procédant de manière logique (Logical Computing Machine) – les fameuses machines de Turing, capables d’effectuer mécaniquement tous les algorithmes possibles et imaginables, déjà découverts ou qui le seront jusqu’à la fin des temps.
La thèse, dite de Church-Turing, selon laquelle tous les algorithmes sont représentables et effectuables sur une Machine de Turing, est aujourd’hui universellement acceptée. Il a même été démontré de manière formelle que les mécanismes de toutes les machines obéissant aux lois de la physique classique (newtonienne), aussi complexes soient-ils, ne pourront jamais réaliser des opérations qui ne soient pas assimilables (moyennant les correspondances adéquates) à un calcul sur une machine de Turing.
Or une telle machine n’est pas un monstre de complexité que l’humanité devra attendre des millénaires avant de posséder. C’est un modèle d’une simplicité extrême, et nos ordinateurs actuels sont bien plus complexes, dans leur conception et dans leur fonctionnement, qu’une machine de Turing élémentaire.
Voilà pourquoi ce qu’une telle machine peut faire, tout ordinateur moderne peut également le faire : calculer tout ce qui est calculable, mettre en œuvre n’importe quel algorithme. Les seules limitations ne sont ni mathématiques, ni conceptuelles, mais liées à la physique : il s’agit de la vitesse de calcul et de la mémoire disponible qui, même si elles augmentent chaque année de manière vertigineuse, ne seront jamais infinies. D’où l’importance d’identifier des algorithmes efficaces, et de représenter les données utiles de la manière la plus adéquate possible." > L_importance_des_ordinateurs.txt

echo "Quelle que soit leur puissance théorique, les machines informatiques réelles sont soumises à des limitations physiques touchant à la puissance de calcul, c’est-à-dire le nombre d’opérations élémentaires pouvant être effectuées chaque seconde, ainsi qu’à la mémoire disponible, c’est-à-dire la quantité d’informations qu’un programme peut avoir à disposition, ou auxquelles il peut accéder à tout moment en un temps raisonnable. On peut ainsi évaluer le « coût » d’une opération informatique ou d’un calcul, au sens large, par le temps et la mémoire que nécessite son exécution.
Une part importante de la recherche en algorithmique consiste à élaborer des algorithmes de plus en plus efficaces, c’est-à-dire ayant un « coût » le plus faible possible. Il apparaît souvent qu’un effort d’analyse important au moment de la conception permet de mettre au point des algorithmes extrêmement puissants vis-à-vis des applications, avec des gains de temps exceptionnels. Prenons l’exemple, non mathématique, de l’art du découpage japonais. Pour produire un motif géométrique compliqué dans une feuille de papier, on peut naïvement faire des trous aux ciseaux, un peu partout.
Mais cette manière de procéder est à la fois difficile, longue et imprécise. Une autre méthode consiste à effectuer d’abord des pliages astucieux, pour ne donner ensuite que deux ou trois coups de ciseaux dans un coin (ce qui est très facile), et déplier la feuille. Le résultat sera invariablement plus précis (la symétrie étant automatique), et obtenu plus rapidement, avec bien moins de coups de ciseaux.
La difficulté a été déplacée dans l’identification du bon algorithme, c’est-à-dire ici la succession et la localisation des pliages et des coups de ciseaux adéquats. Pour résoudre un même problème, on peut souvent utiliser différents algorithmes, qui n’ont pas tous la même complexité. Ainsi, le calcul du PGCD (plus grand commun diviseur) de deux nombres entiers naturels non nuls peut être effectué de bien des manières. Il est possible de trouver le résultat en essayant la division par tous les entiers, mais le mathématicien grec Euclide a trouvé une méthode plus élégante, connue sous le nom d’algorithme d’Euclide.
L’idée est la suivante : on divise le plus grand des deux nombres par le plus petit des deux, puis le plus petit des deux par le reste de la première division euclidienne. On recommence jusqu’à ce que le reste (qui diminue sans cesse) devienne nul. Le PGCD cherché est le dernier reste non nul (ou le premier diviseur, si le premier reste est nul)." > Algorithmes_en_recherche_d_efficacité.txt

echo "Le concept d'algorithme est le plus ancien, puisque 2 500 ans avant notre ère, les comptables utilisaient déjà des algorithmes pour effectuer les quatre opérations, calculer des prêts, des héritages... et les arpenteurs pour calculer l'aire de surfaces agricoles.
Ce concept d'algorithme n'est pas propre à l'informatique, puisqu'il est également utilisé en mathématiques, où existent de nombreux algorithmes pour résoudre des équations de manière exacte ou approchée, dériver et intégrer des expressions fonctionnelles, calculer la probabilité de certains événements... Si on fait démarrer l'informatique dans les années 1930, ce concept est donc bien antérieur à l'informatique, mais si on fait démarrer les mathématiques au Ve siècle avant notre ère, il est également antérieur aux mathématiques. Un algorithme est une recette qui permet de résoudre un certain problème de manière systématique. Un exemple paradigmatique est la recette de la tarte aux pommes, qui permet de résoudre un problème : faire une tarte aux pommes. Toutefois, dans cet exemple, il est important de distinguer la recette en tant que texte de la recette en tant que pratique.
Une recette peut être exécutée et même être transmise de génération en génération, sans être écrite, ni même verbalisée. C'est cette seconde notion qui correspond à la notion d'algorithme. Dès que la recette est écrite ou verbalisée, elle doit être comparée, non à la notion d'algorithme, mais à celle de programme." > Le_concept_d_algorithme.txt

cd /home
